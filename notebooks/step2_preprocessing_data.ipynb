{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Social Media Data (Preprocessing Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from os import path as Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing nltk for preprocessing and defining stopwords (not used with transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'mebank','um','umm','ummm','hi','hello','hey','heyyyyy','fyi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing tweet-preprocessor\n",
    "#!pip install tweet-preprocessor\n",
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>date</th>\n      <th>content</th>\n      <th>complaint</th>\n      <th>topic</th>\n      <th>content_type</th>\n      <th>user</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>861</th>\n      <td>573</td>\n      <td>2021-07-25 09:22:13</td>\n      <td>Making beautiful banking and helping Australi...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>twitter/mention</td>\n      <td>sandybeech4</td>\n      <td>https://twitter.com/sandybeech4/status/1419226...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "     Unnamed: 0                 date  \\\n861         573  2021-07-25 09:22:13   \n\n                                               content  complaint topic  \\\n861   Making beautiful banking and helping Australi...          0   NaN   \n\n        content_type         user  \\\n861  twitter/mention  sandybeech4   \n\n                                                   url  \n861  https://twitter.com/sandybeech4/status/1419226...  "
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=pd.read_csv(\"../data/mebank_tweets_1_year_clean.csv\")\n",
    "input_data.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, flg_clean=True, flg_tweet=True, flg_stemm=False, flg_lemm=False, lst_stopwords=None):\n",
    "\n",
    "\t## Tweet preprocessor\n",
    "\tif flg_tweet == True:\n",
    "\t\timport preprocessor as p\n",
    "\t\t# remove url, mention,emoji, smily, and numbers (keeping hashtags)\n",
    "\t\tp.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
    "\t\ttext=p.clean(text)\n",
    "\n",
    "\t## Tweet preprocessor\n",
    "\tif flg_clean == True:\n",
    "\n",
    "\t\t# Remove mentions\n",
    "\t\ttext = re.sub(r'/^(?!.*\\bRT\\b)(?:.+\\s)?@\\w+/i', '', text)\n",
    "\t\ttext = re.sub('@', '', text)\n",
    "\t\t\n",
    "\t\t# Replace Emails\n",
    "\t\ttext = re.sub('\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "\t\t# Remove links\n",
    "\t\ttext = re.sub('http\\S*', '', text)\n",
    "\n",
    "\t\t# clean hashtags (just removing the hashtag)\n",
    "\t\t# #text = re.sub('#\\S*', '', text)\n",
    "\t\ttext = re.sub('#', '', text)\n",
    "\n",
    "\t\t# Remove unacceptable characters/emojis\n",
    "\t\ttext = re.sub('\\S*ü\\S*\\s?', '', text)\n",
    "\t\ttext = re.sub('\\S*ò\\S*\\s?', '', text)\n",
    "\t\ttext = re.sub('\\S*ä\\S*\\s?', '', text)\n",
    "\t\ttext = re.sub('\\S*ô\\S*\\s?', '', text)\n",
    "\n",
    "\n",
    "\t\t# Remove new line characters\n",
    "\t\ttext = re.sub('\\s+', ' ', text)\n",
    "\n",
    "\t\t# convert to lower case\n",
    "\t\ttext=text.lower()\n",
    "\n",
    "\t\t## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "\t\t#text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "\t\t\n",
    "\t\t# Remove distracting single quotes\n",
    "\t\t#text = [re.sub(\"\\'\", \"\", sent) for sent in text]\n",
    "\n",
    "\t\t\t\n",
    "\t## Tokenize (convert from string to list)\n",
    "\tlst_text = text.split()    ## remove Stopwords\n",
    "\n",
    "\tif lst_stopwords is not None:\n",
    "\t\tlst_text = [word for word in lst_text if word not in lst_stopwords]\n",
    "\t\t\n",
    "\t## Stemming (remove -ing, -ly, ...)\n",
    "\tif flg_stemm == True:\n",
    "\t\tps = nltk.stem.porter.PorterStemmer()\n",
    "\t\tlst_text = [ps.stem(word) for word in lst_text]\n",
    "\t\t\n",
    "\t## Lemmatisation (convert the word into root word)\n",
    "\tif flg_lemm == True:\n",
    "\t\tlem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\t\tlst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\t\t\n",
    "\t## back to string from list\n",
    "\ttext = \" \".join(lst_text)\n",
    "\t\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring preprocessing output using text examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'yes system down. #mebank #route mebank Not noot playing umm we would look into these yes, nd line'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
    "p.clean('yes system down. @marchall #mebank #route http:yes.com mebank Not noot playing umm we would look into these \\n yes, 2nd line 1200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'yes . mebank route mebank not playing umm we would look into these yes, nd line'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_text('yes @marchall. #mebank #route http:yes.com mebank not playing umm we would look into these \\n yes, 2nd line 1200', \\\n",
    "\tflg_tweet=True, flg_clean=True, flg_stemm=False, flg_lemm=False, lst_stopwords=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(input_data['content'])):\n",
    "\tinput_data.loc[i,'content_clean']=preprocess_text(input_data.loc[i,'content'], flg_clean=True, flg_tweet=True, flg_stemm=False, flg_lemm=False, lst_stopwords=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>content</th>\n      <th>content_clean</th>\n      <th>complaint</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>861</th>\n      <td>2021-07-25 09:22:13</td>\n      <td>Making beautiful banking and helping Australi...</td>\n      <td>making beautiful banking and helping australia...</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    date                                            content  \\\n861  2021-07-25 09:22:13   Making beautiful banking and helping Australi...   \n\n                                         content_clean  complaint topic  \n861  making beautiful banking and helping australia...          0   NaN  "
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=input_data[['date','content','content_clean','complaint','topic']]\n",
    "input_data.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the preprocessed data in local dir\n",
    "input_data.to_csv(\"../data/mebank_tweets_1_year_preprocessed.csv\", index=False)\n",
    "\n",
    "#saving the preprocessed data in s3 bucket\n",
    "#input_data.to_csv(f\"{s3_data_dir}/preprocessed/mebank_tweets_1_year_preprocessed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python388jvsc74a57bd0ff644ce4490e00758abe9147b52402080b94cb6ac107623a27054040ad7b1c9e"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}